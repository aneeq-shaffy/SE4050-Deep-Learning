{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkRwfaT9X2LmAUBC0EvKp6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aneeq-shaffy/SE4050-Deep-Learning/blob/main/XLM_RoBERTa_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "425a28e4"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9d52cbf"
      },
      "source": [
        "### Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "H3EZvjKSg5Th"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import (\n",
        "    XLMRobertaTokenizer,\n",
        "    XLMRobertaForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import json\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read Dataset"
      ],
      "metadata": {
        "id": "rwlSpFiLqq5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_lk_news_automatically(year='2021', num_articles=99999):\n",
        "    # Get folder list from GitHub\n",
        "    api_url = f\"https://api.github.com/repos/nuuuwan/lk_news/contents/data/lk_news/2020s/{year}?ref=data\"\n",
        "    response = requests.get(api_url)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(\"Error getting folder list\")\n",
        "        return None\n",
        "\n",
        "    folders = response.json()\n",
        "    print(f\"Found {len(folders)} articles in {year}\")\n",
        "\n",
        "    all_articles = []\n",
        "    base_url = f\"https://raw.githubusercontent.com/nuuuwan/lk_news/data/data/lk_news/2020s/{year}\"\n",
        "\n",
        "    # Download each article\n",
        "    for i, folder in enumerate(folders[:num_articles]):\n",
        "        if folder['type'] == 'dir':\n",
        "            folder_name = folder['name']\n",
        "\n",
        "            try:\n",
        "                # Get files\n",
        "                metadata = requests.get(f\"{base_url}/{folder_name}/doc.json\").json()\n",
        "                text = requests.get(f\"{base_url}/{folder_name}/doc.txt\").text\n",
        "\n",
        "                # Store article\n",
        "                all_articles.append({\n",
        "                    'id': metadata.get('doc_id', ''),\n",
        "                    'text': text,\n",
        "                    'title': metadata.get('description', ''),\n",
        "                    'language': metadata.get('lang', ''),\n",
        "                    'date': metadata.get('date_str', '')\n",
        "                })\n",
        "\n",
        "                if (i+1) % 10 == 0:\n",
        "                    print(f\"Loaded {i+1} articles...\")\n",
        "\n",
        "            except:\n",
        "                print(f\"Failed: {folder_name}\")\n",
        "\n",
        "    return pd.DataFrame(all_articles)"
      ],
      "metadata": {
        "id": "onhPDTC4qxHs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_news(years=['2021', '2022', '2023', '2024', '2025'], articles_per_year=50):\n",
        "    all_dfs = []\n",
        "\n",
        "    for year in years:\n",
        "        print(f\"\\nGetting {year}...\")\n",
        "        df_year = read_lk_news_automatically(year, articles_per_year)\n",
        "        if df_year is not None:\n",
        "            all_dfs.append(df_year)\n",
        "\n",
        "    final_df = pd.concat(all_dfs, ignore_index=True)\n",
        "    print(f\"\\n‚úÖ Total: {len(final_df)} articles\")\n",
        "    return final_df"
      ],
      "metadata": {
        "id": "xJ-dxz6RUIEq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the data\n",
        "df = get_all_news(years=['2021', '2022', '2023', '2024', '2025'], articles_per_year=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pY8pRXE0UOjm",
        "outputId": "d48d20bd-b844-4038-c151-12127d67ed06"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Getting 2021...\n",
            "Found 4 articles in 2021\n",
            "\n",
            "Getting 2022...\n",
            "Found 19 articles in 2022\n",
            "Loaded 10 articles...\n",
            "\n",
            "Getting 2023...\n",
            "Found 173 articles in 2023\n",
            "Loaded 10 articles...\n",
            "Loaded 20 articles...\n",
            "Loaded 30 articles...\n",
            "Loaded 40 articles...\n",
            "Loaded 50 articles...\n",
            "\n",
            "Getting 2024...\n",
            "Found 1000 articles in 2024\n",
            "Loaded 10 articles...\n",
            "Loaded 20 articles...\n",
            "Loaded 30 articles...\n",
            "Loaded 40 articles...\n",
            "Loaded 50 articles...\n",
            "\n",
            "Getting 2025...\n",
            "Found 1000 articles in 2025\n",
            "Loaded 10 articles...\n",
            "Loaded 20 articles...\n",
            "Loaded 30 articles...\n",
            "Loaded 40 articles...\n",
            "Loaded 50 articles...\n",
            "\n",
            "‚úÖ Total: 173 articles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See what you got\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"Columns: {df.columns.tolist()}\")\n",
        "print(\"\\nFirst article:\")\n",
        "print(df.iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCY8h_VoUPID",
        "outputId": "32768ffa-bddc-4aca-e17f-9213274b7095"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (173, 5)\n",
            "Columns: ['id', 'text', 'title', 'language', 'date']\n",
            "\n",
            "First article:\n",
            "id                                  2021-09-12-adalk-095b8035\n",
            "text        ‡∂±‡∑ú‡∑Ä‡∑ê‡∂∏‡∑ä‡∂∂‡∂ª‡∑ä ‡∂∏‡∑É ‡∑É‡∑í‡∂ß WhatsApp ‡∂Ö‡∂≠‡∑ä‡∑Ñ‡∑í‡∂ß‡∑î‡∑Ä‡∂± ‡∂¢‡∂Ç‡∂ú‡∂∏ ‡∂Ø‡∑î‡∂ª‡∂ö‡∂Æ...\n",
            "title       ‡∂±‡∑ú‡∑Ä‡∑ê‡∂∏‡∑ä‡∂∂‡∂ª‡∑ä ‡∂∏‡∑É ‡∑É‡∑í‡∂ß WhatsApp ‡∂Ö‡∂≠‡∑ä‡∑Ñ‡∑í‡∂ß‡∑î‡∑Ä‡∂± ‡∂¢‡∂Ç‡∂ú‡∂∏ ‡∂Ø‡∑î‡∂ª‡∂ö‡∂Æ...\n",
            "language                                                   si\n",
            "date                                               2021-09-12\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to CSV\n",
        "df.to_csv('lk_news_data.csv', index=False)\n",
        "print(\"üíæ Saved to lk_news_data.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYDC9psjURXq",
        "outputId": "5d55459a-41d4-4943-fbf6-9976b2fa8797"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Saved to lk_news_data.csv\n"
          ]
        }
      ]
    }
  ]
}