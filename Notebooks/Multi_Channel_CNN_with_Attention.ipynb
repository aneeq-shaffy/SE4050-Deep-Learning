{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install Required Libraries"
      ],
      "metadata": {
        "id": "SYPb0iPmAsIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow keras pandas scikit-learn -q\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, backend as K\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB5Nvfd4AtlF",
        "outputId": "4ac60da8-7e0f-4453-bb3e-cf79c40cd35c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "GPU Available: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and Explore Data"
      ],
      "metadata": {
        "id": "-itB0n8nBDFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "df = pd.read_csv('news_preprocessed.csv')\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(f\"\\nUnique categories: {df['category'].nunique()}\")\n",
        "print(f\"\\nLabel distribution:\")\n",
        "print(df['label'].value_counts().sort_index())\n",
        "\n",
        "# Check text lengths\n",
        "df['text_length'] = df['text'].apply(lambda x: len(str(x).split()))\n",
        "print(f\"\\nText length statistics:\")\n",
        "print(df['text_length'].describe())\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.hist(df['text_length'], bins=50, edgecolor='black')\n",
        "plt.xlabel('Number of Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Text Lengths')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R77a7GleA50f",
        "outputId": "cb8dc517-7483-4cb8-90ea-a57a9f2bffa6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (30000, 3)\n",
            "\n",
            "Columns: ['text', 'category', 'label']\n",
            "\n",
            "First few rows:\n",
            "                                                text       category  label\n",
            "0  ethan hawke julie delpy pick left midnight eth...  ENTERTAINMENT      3\n",
            "1  tom cruise forced choose scientology suri tom ...  ENTERTAINMENT      3\n",
            "2  would pay wine beer glass made cheese heart me...  ENTERTAINMENT      3\n",
            "3                    tyga denies dating kylie jenner  ENTERTAINMENT      3\n",
            "4  review laughfest subversively family friendly ...  ENTERTAINMENT      3\n",
            "\n",
            "Unique categories: 15\n",
            "\n",
            "Label distribution:\n",
            "label\n",
            "0     2000\n",
            "1     2000\n",
            "2     2000\n",
            "3     2000\n",
            "4     2000\n",
            "5     2000\n",
            "6     2000\n",
            "7     2000\n",
            "8     2000\n",
            "9     2000\n",
            "10    2000\n",
            "11    2000\n",
            "12    2000\n",
            "13    2000\n",
            "14    2000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Text length statistics:\n",
            "count    30000.000000\n",
            "mean        17.633600\n",
            "std          7.196968\n",
            "min          5.000000\n",
            "25%         13.000000\n",
            "50%         17.000000\n",
            "75%         22.000000\n",
            "max        108.000000\n",
            "Name: text_length, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1sAAAGJCAYAAAB8VSkIAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAT8lJREFUeJzt3XlYFvX+//HXLTsoohDcIosk5r6lpRxNUUlUNEs7pbkvefRguaXmqdQ0l+zgmmmr1lFL20tzwT0LTU3SFMktsWQJFxAXQJjfH/28v925AXJ7izwf1zXX5Xzm85l5z+2ck69rZj5jMgzDEAAAAACgWJWxdwEAAAAAcDcibAEAAACADRC2AAAAAMAGCFsAAAAAYAOELQAAAACwAcIWAAAAANgAYQsAAAAAbICwBQAAAAA2QNgCAAAAABsgbAHAHW7ixIkymUy35Vjh4eEKDw+3rG/evFkmk0mffPLJbTl+3759VaVKldtyrKLKysrSwIEDZTabZTKZNHz4cHuXVKrc7msSAG4FYQsAbqPFixfLZDJZFldXV/n7+ysyMlJz587VuXPniuU4J0+e1MSJExUfH18s+ytOd3JtBTF16lQtXrxYQ4YM0f/+9z/16tXrqj5XAvLNlr8G21u1bNkyzZ49u8D9q1Spoo4dOxbb8YtbYc8HAO5EjvYuAABKo0mTJikkJES5ublKSUnR5s2bNXz4cM2cOVNfffWV6tWrZ+n74osv6vnnny/U/k+ePKmXX35ZVapUUYMGDQo8bt26dYU6TlHcqLa3335b+fn5Nq/hVmzcuFFNmzbVhAkTrtunS5cuCg0NtaxnZWVpyJAheuyxx9SlSxdLu5+fX7HVtWzZMv388893zZ22u+18AJROhC0AsIP27durcePGlvVx48Zp48aN6tixox555BElJCTIzc1NkuTo6ChHR9v+3/WFCxfk7u4uZ2dnmx7nZpycnOx6/IJIS0tTrVq1btinXr16VoE5PT1dQ4YMUb169dSzZ09blwgAuEPwGCEA3CFat26tl156ScePH9eSJUss7dd6Zys2NlbNmzeXl5eXypYtq+rVq+s///mPpD/faXnggQckSf369bM8srZ48WJJf76XVadOHe3evVstWrSQu7u7Zezf39m6Ii8vT//5z39kNpvl4eGhRx55RCdOnLDqU6VKFfXt2/eqsX/d581qu9Y7W+fPn9eoUaMUGBgoFxcXVa9eXf/9739lGIZVP5PJpKFDh+qLL75QnTp15OLiotq1a2vNmjXX/sH/Ji0tTQMGDJCfn59cXV1Vv359vf/++5btV94VOnbsmFatWmWp/ddffy3Q/q/l4MGDevzxx1WxYkW5urqqcePG+uqrr6xquueeexQeHm51vocPH5aHh4eefPJJSX/+xqtWrdLx48ctdRXXu29LlixRo0aN5ObmpooVK6pbt25X/d1fuaYOHDigVq1ayd3dXZUrV9aMGTOu2t/x48f1yCOPyMPDQ76+vhoxYoTWrl0rk8mkzZs3F/h88vPzNWXKFAUEBMjV1VVt2rTR4cOHrfocOnRIXbt2ldlslqurqwICAtStWzdlZGQUy28DADfDnS0AuIP06tVL//nPf7Ru3To9/fTT1+yzf/9+dezYUfXq1dOkSZPk4uKiw4cP67vvvpMk1axZU5MmTdL48eM1aNAgPfTQQ5Kkf/zjH5Z9nDp1Su3bt1e3bt3Us2fPmz7ONmXKFJlMJo0dO1ZpaWmaPXu2IiIiFB8fb7kDVxAFqe2vDMPQI488ok2bNmnAgAFq0KCB1q5dq9GjR+v333/XrFmzrPpv27ZNn332mf7973+rXLlymjt3rrp27aqkpCR5e3tft66LFy8qPDxchw8f1tChQxUSEqKPP/5Yffv21dmzZzVs2DDVrFlT//vf/zRixAgFBARo1KhRkqR77rmnwOf/V/v371ezZs1UuXJlPf/88/Lw8NCKFSv06KOP6tNPP9Vjjz0mX19fLViwQP/85z81b948Pfvss8rPz1ffvn1Vrlw5vfHGG5KkF154QRkZGfrtt98sv0nZsmWLVNdfTZkyRS+99JKeeOIJDRw4UH/88YfmzZunFi1aaM+ePfLy8rL0PXPmjNq1a6cuXbroiSee0CeffKKxY8eqbt26at++vaQ/g3Pr1q2VnJysYcOGyWw2a9myZdq0aZPVcQtyPtOnT1eZMmX03HPPKSMjQzNmzFCPHj20Y8cOSVJOTo4iIyOVnZ2tZ555RmazWb///rtWrlyps2fPqnz58rf8+wDATRkAgNtm0aJFhiRj586d1+1Tvnx5o2HDhpb1CRMmGH/9v+tZs2YZkow//vjjuvvYuXOnIclYtGjRVdtatmxpSDIWLlx4zW0tW7a0rG/atMmQZFSuXNnIzMy0tK9YscKQZMyZM8fSFhwcbPTp0+em+7xRbX369DGCg4Mt61988YUhyXjllVes+j3++OOGyWQyDh8+bGmTZDg7O1u1/fTTT4YkY968eVcd669mz55tSDKWLFliacvJyTHCwsKMsmXLWp17cHCwERUVdcP9/d0ff/xhSDImTJhgaWvTpo1Rt25d49KlS5a2/Px84x//+IdRrVo1q/Hdu3c33N3djV9++cV47bXXDEnGF198YdUnKirK6re7mZudx6+//mo4ODgYU6ZMsWrft2+f4ejoaNV+5Zr64IMPLG3Z2dmG2Ww2unbtammLiYm5qvaLFy8aNWrUMCQZmzZtuun5XLkma9asaWRnZ1va58yZY0gy9u3bZxiGYezZs8eQZHz88cc3/zEAwEZ4jBAA7jBly5a94ayEV+4mfPnll0WeTMLFxUX9+vUrcP/evXurXLlylvXHH39clSpV0jfffFOk4xfUN998IwcHBz377LNW7aNGjZJhGFq9erVVe0REhKpWrWpZr1evnjw9PXX06NGbHsdsNqt79+6WNicnJz377LPKysrSli1biuFs/s/p06e1ceNGPfHEEzp37pzS09OVnp6uU6dOKTIyUocOHdLvv/9u6f/666+rfPnyevzxx/XSSy+pV69e6ty5c7HW9HefffaZ8vPz9cQTT1jqS09Pl9lsVrVq1a66G1W2bFmr99GcnZ314IMPWv32a9asUeXKlfXII49Y2lxdXa97F/dG+vXrZ/WO4ZW7pFeOd+XO1dq1a3XhwoVC7x8AigNhCwDuMFlZWVbB5u+efPJJNWvWTAMHDpSfn5+6deumFStWFCp4Va5cuVCTYVSrVs1q3WQyKTQ09JbeVyqI48ePy9/f/6rfo2bNmpbtfxUUFHTVPipUqKAzZ87c9DjVqlVTmTLW/1m83nFu1eHDh2UYhl566SXdc889VsuVWQ7T0tIs/StWrKi5c+dq7969Kl++vObOnVus9VzLoUOHZBiGqlWrdlWNCQkJVvVJUkBAwFXvFv79tz9+/LiqVq16Vb+/ztxYUH//u65QoYIkWY4XEhKikSNH6p133pGPj48iIyM1f/583tcCcFvxzhYA3EF+++03ZWRk3PAfn25ubtq6das2bdqkVatWac2aNVq+fLlat26tdevWycHB4abHKcx7VgV1vQ8v5+XlFaim4nC94xh/m0zD3q4E4+eee06RkZHX7PP3a2Dt2rWS/gwTv/32m9X7Uraq0WQyafXq1df8Xf/+DtXt/u0LcryYmBj17dtXX375pdatW6dnn31W06ZN0/bt2xUQEGCTugDgrwhbAHAH+d///idJ1/0H+BVlypRRmzZt1KZNG82cOVNTp07VCy+8oE2bNikiIuK6waeoDh06ZLVuGIYOHz5sNb15hQoVdPbs2avGHj9+XPfee69lvTC1BQcHa/369Tp37pzV3a2DBw9atheH4OBg7d27V/n5+VZ3t4r7OFdc+T2cnJwUERFx0/5r1qzRO++8ozFjxmjp0qXq06ePduzYYfVJgOL+O69ataoMw1BISIjuu+++YtlncHCwDhw4IMMwrOr9+yyCUvGdT926dVW3bl29+OKL+v7779WsWTMtXLhQr7zySrHsHwBuhMcIAeAOsXHjRk2ePFkhISHq0aPHdfudPn36qrYrHwfOzs6WJHl4eEjSNcNPUXzwwQdW75F98sknSk5OtswyJ/35j/Pt27crJyfH0rZy5cqrpgkvTG0dOnRQXl6eXn/9dav2WbNmyWQyWR3/VnTo0EEpKSlavny5pe3y5cuaN2+eypYtq5YtWxbLca7w9fVVeHi43nzzTSUnJ1+1/Y8//rD8+ezZsxo4cKAefPBBTZ06Ve+8845+/PFHTZ061WqMh4dHsT4i16VLFzk4OOjll1++6u6UYRg6depUofcZGRmp33//3Wp6+0uXLuntt9++qu+tnk9mZqYuX75s1Va3bl2VKVPG8r8TALA17mwBgB2sXr1aBw8e1OXLl5WamqqNGzcqNjZWwcHB+uqrr+Tq6nrdsZMmTdLWrVsVFRWl4OBgpaWl6Y033lBAQICaN28u6c/g4+XlpYULF6pcuXLy8PBQkyZNFBISUqR6K1asqObNm6tfv35KTU3V7NmzFRoaajWxwcCBA/XJJ5+oXbt2euKJJ3TkyBEtWbLEasKKwtbWqVMntWrVSi+88IJ+/fVX1a9fX+vWrdOXX36p4cOHX7Xvoho0aJDefPNN9e3bV7t371aVKlX0ySef6LvvvtPs2bNv+A5dUc2fP1/NmzdX3bp19fTTT+vee+9Vamqq4uLi9Ntvv+mnn36SJA0bNkynTp3S+vXr5eDgoHbt2mngwIF65ZVX1LlzZ9WvX1+S1KhRIy1fvlwjR47UAw88oLJly6pTp043rOHw4cPXvMPTsGFDRUVF6ZVXXtG4ceP066+/6tFHH1W5cuV07Ngxff755xo0aJCee+65Qp3zv/71L73++uvq3r27hg0bpkqVKmnp0qWW6/2vd7OKcj5/tXHjRg0dOlT//Oc/dd999+ny5cv63//+JwcHB3Xt2rVQdQNAkdlpFkQAKJWuTP1+ZXF2djbMZrPx8MMPG3PmzLGaYvyKv0/9vmHDBqNz586Gv7+/4ezsbPj7+xvdu3c3fvnlF6txX375pVGrVi3D0dHRaqr1li1bGrVr175mfdeb+v3DDz80xo0bZ/j6+hpubm5GVFSUcfz48avGx8TEGJUrVzZcXFyMZs2aGbt27bpqnzeq7e9TvxuGYZw7d84YMWKE4e/vbzg5ORnVqlUzXnvtNSM/P9+qnyQjOjr6qpquNyX936Wmphr9+vUzfHx8DGdnZ6Nu3brXnJ6+uKZ+NwzDOHLkiNG7d2/DbDYbTk5ORuXKlY2OHTsan3zyiWEYf/5OkoyYmBircZmZmUZwcLBRv359IycnxzAMw8jKyjKeeuopw8vLy5B002ngg4ODra7Fvy4DBgyw9Pv000+N5s2bGx4eHoaHh4dRo0YNIzo62khMTLT0ud41da2/z6NHjxpRUVGGm5ubcc899xijRo0yPv30U0OSsX37dku/653PlWvy71O6Hzt2zOpaOnr0qNG/f3+jatWqhqurq1GxYkWjVatWxvr162/4uwBAcTIZxh321jAAAChVZs+erREjRui3335T5cqV7V0OABQbwhYAALhtLl68aDUb5qVLl9SwYUPl5eXpl19+sWNlAFD8eGcLAADcNl26dFFQUJAaNGigjIwMLVmyRAcPHtTSpUvtXRoAFDvCFgAAuG0iIyP1zjvvaOnSpcrLy1OtWrX00Ucf6cknn7R3aQBQ7HiMEAAAAABsgO9sAQAAAIANELYAAAAAwAZ4Z6sA8vPzdfLkSZUrV87qg4sAAAAAShfDMHTu3Dn5+/urTJkb37sibBXAyZMnFRgYaO8yAAAAANwhTpw4oYCAgBv2IWwVQLly5ST9+YN6enrauRoAAAAA9pKZmanAwEBLRrgRwlYBXHl00NPTk7AFAAAAoECvFzFBBgAAAADYAGELAAAAAGyAsAUAAAAANkDYAgAAAAAbIGwBAAAAgA0QtgAAAADABghbAAAAAGADhC0AAAAAsAHCFgAAAADYAGELAAAAAGzA0d4FAHeCpKQkpaenF3qcj4+PgoKCbFARAAAASjrCFkq9pKQkVa9RU5cuXij0WFc3dyUeTCBwAQAA4CqELZR66enpunTxgrw7jpKTd2CBx+WeOqFTK2OUnp5O2AIAAMBVCFvA/+fkHSgXc6i9ywAAAMBdgrCFu0pR3r1KSEiwUTUAAAAozQhbuGvcyrtXAAAAQHEjbOGuUdR3ry4e3aWMb5fYsDIAAACURoQt3HUK++5V7qkTNqwGAAAApRUfNQYAAAAAGyBsAQAAAIANELYAAAAAwAYIWwAAAABgA4QtAAAAALABwhYAAAAA2ABhCwAAAABsgLAFAAAAADZA2AIAAAAAGyBsAQAAAIAN2DVsLViwQPXq1ZOnp6c8PT0VFham1atXW7aHh4fLZDJZLYMHD7baR1JSkqKiouTu7i5fX1+NHj1aly9ftuqzefNm3X///XJxcVFoaKgWL158O04PAAAAQCnmaM+DBwQEaPr06apWrZoMw9D777+vzp07a8+ePapdu7Yk6emnn9akSZMsY9zd3S1/zsvLU1RUlMxms77//nslJyerd+/ecnJy0tSpUyVJx44dU1RUlAYPHqylS5dqw4YNGjhwoCpVqqTIyMjbe8IAAAAASg27hq1OnTpZrU+ZMkULFizQ9u3bLWHL3d1dZrP5muPXrVunAwcOaP369fLz81ODBg00efJkjR07VhMnTpSzs7MWLlyokJAQxcTESJJq1qypbdu2adasWYQtAAAAADZzx7yzlZeXp48++kjnz59XWFiYpX3p0qXy8fFRnTp1NG7cOF24cMGyLS4uTnXr1pWfn5+lLTIyUpmZmdq/f7+lT0REhNWxIiMjFRcXd91asrOzlZmZabUAAAAAQGHY9c6WJO3bt09hYWG6dOmSypYtq88//1y1atWSJD311FMKDg6Wv7+/9u7dq7FjxyoxMVGfffaZJCklJcUqaEmyrKekpNywT2Zmpi5evCg3N7erapo2bZpefvnlYj9XAAAAAKWH3cNW9erVFR8fr4yMDH3yySfq06ePtmzZolq1amnQoEGWfnXr1lWlSpXUpk0bHTlyRFWrVrVZTePGjdPIkSMt65mZmQoMDLTZ8QAAAADcfez+GKGzs7NCQ0PVqFEjTZs2TfXr19ecOXOu2bdJkyaSpMOHD0uSzGazUlNTrfpcWb/yntf1+nh6el7zrpYkubi4WGZIvLIAAAAAQGHYPWz9XX5+vrKzs6+5LT4+XpJUqVIlSVJYWJj27duntLQ0S5/Y2Fh5enpaHkUMCwvThg0brPYTGxtr9V4YAAAAABQ3uz5GOG7cOLVv315BQUE6d+6cli1bps2bN2vt2rU6cuSIli1bpg4dOsjb21t79+7ViBEj1KJFC9WrV0+S1LZtW9WqVUu9evXSjBkzlJKSohdffFHR0dFycXGRJA0ePFivv/66xowZo/79+2vjxo1asWKFVq1aZc9TBwAAAHCXs2vYSktLU+/evZWcnKzy5curXr16Wrt2rR5++GGdOHFC69ev1+zZs3X+/HkFBgaqa9euevHFFy3jHRwctHLlSg0ZMkRhYWHy8PBQnz59rL7LFRISolWrVmnEiBGaM2eOAgIC9M477zDtOwAAAACbsmvYevfdd6+7LTAwUFu2bLnpPoKDg/XNN9/csE94eLj27NlT6PoAAAAAoKjuuHe2AAAAAOBuYPep34FrSUpKUnp6eqHGJCQk2KgaAAAAoPAIW7jjJCUlqXqNmrp08YK9SwEAAACKjLCFO056erouXbwg746j5ORd8I9JXzy6SxnfLrFhZQAAAEDBEbZwx3LyDpSLObTA/XNPnbBhNQAAAEDhMEEGAAAAANgAYQsAAAAAbICwBQAAAAA2QNgCAAAAABsgbAEAAACADRC2AAAAAMAGCFsAAAAAYAOELQAAAACwAcIWAAAAANgAYQsAAAAAbICwBQAAAAA2QNgCAAAAABsgbAEAAACADRC2AAAAAMAGCFsAAAAAYAOELQAAAACwAcIWAAAAANgAYQsAAAAAbICwBQAAAAA2QNgCAAAAABtwtHcBQEmXkJBQ6DE+Pj4KCgqyQTUAAAC4UxC2gCLKyzojmUzq2bNnoce6urkr8WACgQsAAOAuRtgCiig/O0syDHl3HCUn78ACj8s9dUKnVsYoPT2dsAUAAHAXs+s7WwsWLFC9evXk6ekpT09PhYWFafXq1Zbtly5dUnR0tLy9vVW2bFl17dpVqampVvtISkpSVFSU3N3d5evrq9GjR+vy5ctWfTZv3qz7779fLi4uCg0N1eLFi2/H6aGUcPIOlIs5tMBLYYIZAAAASi67hq2AgABNnz5du3fv1q5du9S6dWt17txZ+/fvlySNGDFCX3/9tT7++GNt2bJFJ0+eVJcuXSzj8/LyFBUVpZycHH3//fd6//33tXjxYo0fP97S59ixY4qKilKrVq0UHx+v4cOHa+DAgVq7du1tP18AAAAApYddHyPs1KmT1fqUKVO0YMECbd++XQEBAXr33Xe1bNkytW7dWpK0aNEi1axZU9u3b1fTpk21bt06HThwQOvXr5efn58aNGigyZMna+zYsZo4caKcnZ21cOFChYSEKCYmRpJUs2ZNbdu2TbNmzVJkZORtP2cAAAAApcMdM/V7Xl6ePvroI50/f15hYWHavXu3cnNzFRERYelTo0YNBQUFKS4uTpIUFxenunXrys/Pz9InMjJSmZmZlrtjcXFxVvu40ufKPq4lOztbmZmZVgsAAAAAFIbdw9a+fftUtmxZubi4aPDgwfr8889Vq1YtpaSkyNnZWV5eXlb9/fz8lJKSIklKSUmxClpXtl/ZdqM+mZmZunjx4jVrmjZtmsqXL29ZAgN5xwYAAABA4dg9bFWvXl3x8fHasWOHhgwZoj59+ujAgQN2rWncuHHKyMiwLCdOnLBrPQAAAABKHrtP/e7s7KzQ0FBJUqNGjbRz507NmTNHTz75pHJycnT27Fmru1upqakym82SJLPZrB9++MFqf1dmK/xrn7/PYJiamipPT0+5ubldsyYXFxe5uLgUy/kBAAAAKJ3sfmfr7/Lz85Wdna1GjRrJyclJGzZssGxLTExUUlKSwsLCJElhYWHat2+f0tLSLH1iY2Pl6empWrVqWfr8dR9X+lzZBwAAAADYgl3vbI0bN07t27dXUFCQzp07p2XLlmnz5s1au3atypcvrwEDBmjkyJGqWLGiPD099cwzzygsLExNmzaVJLVt21a1atVSr169NGPGDKWkpOjFF19UdHS05c7U4MGD9frrr2vMmDHq37+/Nm7cqBUrVmjVqlX2PHUAAAAAdzm7hq20tDT17t1bycnJKl++vOrVq6e1a9fq4YcfliTNmjVLZcqUUdeuXZWdna3IyEi98cYblvEODg5auXKlhgwZorCwMHl4eKhPnz6aNGmSpU9ISIhWrVqlESNGaM6cOQoICNA777zDtO8AAAAAbMquYevdd9+94XZXV1fNnz9f8+fPv26f4OBgffPNNzfcT3h4uPbs2VOkGgEAAACgKO64d7YAAAAA4G5A2AIAAAAAGyBsAQAAAIANELYAAAAAwAYIWwAAAABgA4QtAAAAALABwhYAAAAA2ABhCwAAAABsgLAFAAAAADZA2AIAAAAAGyBsAQAAAIANELYAAAAAwAYIWwAAAABgA4QtAAAAALABwhYAAAAA2ABhCwAAAABsgLAFAAAAADZA2AIAAAAAGyBsAQAAAIANONq7ANzdkpKSlJ6eXqgxCQkJNqoGAAAAuH0IW7CZpKQkVa9RU5cuXrB3KQAAAMBtR9iCzaSnp+vSxQvy7jhKTt6BBR538eguZXy7xIaVAQAAALZH2ILNOXkHysUcWuD+uadO2LAaAAAA4PZgggwAAAAAsAHCFgAAAADYAGELAAAAAGyAsAUAAAAANkDYAgAAAAAbsGvYmjZtmh544AGVK1dOvr6+evTRR5WYmGjVJzw8XCaTyWoZPHiwVZ+kpCRFRUXJ3d1dvr6+Gj16tC5fvmzVZ/Pmzbr//vvl4uKi0NBQLV682NanBwAAAKAUs2vY2rJli6Kjo7V9+3bFxsYqNzdXbdu21fnz5636Pf3000pOTrYsM2bMsGzLy8tTVFSUcnJy9P333+v999/X4sWLNX78eEufY8eOKSoqSq1atVJ8fLyGDx+ugQMHau3atbftXAEAAACULnb9ztaaNWus1hcvXixfX1/t3r1bLVq0sLS7u7vLbDZfcx/r1q3TgQMHtH79evn5+alBgwaaPHmyxo4dq4kTJ8rZ2VkLFy5USEiIYmJiJEk1a9bUtm3bNGvWLEVGRtruBAEAAACUWnfUO1sZGRmSpIoVK1q1L126VD4+PqpTp47GjRunCxcuWLbFxcWpbt268vPzs7RFRkYqMzNT+/fvt/SJiIiw2mdkZKTi4uKuWUd2drYyMzOtFgAAAAAoDLve2fqr/Px8DR8+XM2aNVOdOnUs7U899ZSCg4Pl7++vvXv3auzYsUpMTNRnn30mSUpJSbEKWpIs6ykpKTfsk5mZqYsXL8rNzc1q27Rp0/Tyyy8X+zkCAAAAKD3umLAVHR2tn3/+Wdu2bbNqHzRokOXPdevWVaVKldSmTRsdOXJEVatWtUkt48aN08iRIy3rmZmZCgwMtMmxAAAAANyd7ojHCIcOHaqVK1dq06ZNCggIuGHfJk2aSJIOHz4sSTKbzUpNTbXqc2X9ynte1+vj6el51V0tSXJxcZGnp6fVAgAAAACFYdewZRiGhg4dqs8//1wbN25USEjITcfEx8dLkipVqiRJCgsL0759+5SWlmbpExsbK09PT9WqVcvSZ8OGDVb7iY2NVVhYWDGdCQAAAABYs2vYio6O1pIlS7Rs2TKVK1dOKSkpSklJ0cWLFyVJR44c0eTJk7V79279+uuv+uqrr9S7d2+1aNFC9erVkyS1bdtWtWrVUq9evfTTTz9p7dq1evHFFxUdHS0XFxdJ0uDBg3X06FGNGTNGBw8e1BtvvKEVK1ZoxIgRdjt3AAAAAHc3u4atBQsWKCMjQ+Hh4apUqZJlWb58uSTJ2dlZ69evV9u2bVWjRg2NGjVKXbt21ddff23Zh4ODg1auXCkHBweFhYWpZ8+e6t27tyZNmmTpExISolWrVik2Nlb169dXTEyM3nnnHaZ9BwAAAGAzdp0gwzCMG24PDAzUli1bbrqf4OBgffPNNzfsEx4erj179hSqPgAAAAAoqjtiggwAAAAAuNsUKWwdPXq0uOsAAAAAgLtKkcJWaGioWrVqpSVLlujSpUvFXRMAAAAAlHhFCls//vij6tWrp5EjR8psNutf//qXfvjhh+KuDQAAAABKrCKFrQYNGmjOnDk6efKk3nvvPSUnJ6t58+aqU6eOZs6cqT/++KO46wQAAACAEuWWJshwdHRUly5d9PHHH+vVV1/V4cOH9dxzzykwMFC9e/dWcnJycdUJAAAAACXKLYWtXbt26d///rcqVaqkmTNn6rnnntORI0cUGxurkydPqnPnzsVVJwAAAACUKEX6ztbMmTO1aNEiJSYmqkOHDvrggw/UoUMHlSnzZ3YLCQnR4sWLVaVKleKsFQAAAABKjCKFrQULFqh///7q27evKlWqdM0+vr6+evfdd2+pOOBulpCQUOgxPj4+CgoKskE1AAAAKG5FCluHDh26aR9nZ2f16dOnKLsH7mp5WWckk0k9e/Ys9FhXN3clHkwgcAEAAJQARQpbixYtUtmyZfXPf/7Tqv3jjz/WhQsXCFnADeRnZ0mGIe+Oo+TkHVjgcbmnTujUyhilp6cTtgAAAEqAIoWtadOm6c0337yq3dfXV4MGDSJsAQXg5B0oF3OovcsAAACAjRRpNsKkpCSFhIRc1R4cHKykpKRbLgoAAAAASroihS1fX1/t3bv3qvaffvpJ3t7et1wUAAAAAJR0RQpb3bt317PPPqtNmzYpLy9PeXl52rhxo4YNG6Zu3boVd40AAAAAUOIU6Z2tyZMn69dff1WbNm3k6PjnLvLz89W7d29NnTq1WAsEAAAAgJKoSGHL2dlZy5cv1+TJk/XTTz/Jzc1NdevWVXBwcHHXBwAAAAAlUpHC1hX33Xef7rvvvuKqBQAAAADuGkUKW3l5eVq8eLE2bNigtLQ05efnW23fuHFjsRQHAAAAACVVkcLWsGHDtHjxYkVFRalOnToymUzFXRcAAAAAlGhFClsfffSRVqxYoQ4dOhR3PQAAAABwVyjS1O/Ozs4KDQ0t7loAAAAA4K5RpLA1atQozZkzR4ZhFHc9AAAAAHBXKNJjhNu2bdOmTZu0evVq1a5dW05OTlbbP/vss2IpDgAAAABKqiKFLS8vLz322GPFXQsAAAAA3DWKFLYWLVpU3HUAAAAAwF2lSO9sSdLly5e1fv16vfnmmzp37pwk6eTJk8rKyiq24gAAAACgpCrSna3jx4+rXbt2SkpKUnZ2th5++GGVK1dOr776qrKzs7Vw4cLirhMAAAAASpQi3dkaNmyYGjdurDNnzsjNzc3S/thjj2nDhg0F3s+0adP0wAMPqFy5cvL19dWjjz6qxMREqz6XLl1SdHS0vL29VbZsWXXt2lWpqalWfZKSkhQVFSV3d3f5+vpq9OjRunz5slWfzZs36/7775eLi4tCQ0O1ePHiwp84AAAAABRQkcLWt99+qxdffFHOzs5W7VWqVNHvv/9e4P1s2bJF0dHR2r59u2JjY5Wbm6u2bdvq/Pnzlj4jRozQ119/rY8//lhbtmzRyZMn1aVLF8v2vLw8RUVFKScnR99//73ef/99LV68WOPHj7f0OXbsmKKiotSqVSvFx8dr+PDhGjhwoNauXVuU0wcAAACAmyrSY4T5+fnKy8u7qv23335TuXLlCryfNWvWWK0vXrxYvr6+2r17t1q0aKGMjAy9++67WrZsmVq3bi3pz8k5atasqe3bt6tp06Zat26dDhw4oPXr18vPz08NGjTQ5MmTNXbsWE2cOFHOzs5auHChQkJCFBMTI0mqWbOmtm3bplmzZikyMrIoP4HdJSUlKT09vdDjfHx8FBQUdFuOl5CQUOjjAAAAAHeLIoWttm3bavbs2XrrrbckSSaTSVlZWZowYYI6dOhQ5GIyMjIkSRUrVpQk7d69W7m5uYqIiLD0qVGjhoKCghQXF6emTZsqLi5OdevWlZ+fn6VPZGSkhgwZov3796thw4aKi4uz2seVPsOHD79mHdnZ2crOzrasZ2ZmFvmcbCEpKUnVa9TUpYsXCj3W1c1diQcTChW4buV4AAAAQGlVpLAVExOjyMhI1apVS5cuXdJTTz2lQ4cOycfHRx9++GGRCsnPz9fw4cPVrFkz1alTR5KUkpIiZ2dneXl5WfX18/NTSkqKpc9fg9aV7Ve23ahPZmamLl68aPXemfTnu2Qvv/xykc7jdkhPT9elixfk3XGUnLwDCzwu99QJnVoZo/T09EKFraIe7+LRXcr4dkmB+wMAAAB3kyKFrYCAAP3000/66KOPtHfvXmVlZWnAgAHq0aPHVcGloKKjo/Xzzz9r27ZtRRpfnMaNG6eRI0da1jMzMxUYWPCQcbs4eQfKxRx6xx4v99QJG1YDAAAA3NmKFLYkydHRUT179iyWIoYOHaqVK1dq69atCggIsLSbzWbl5OTo7NmzVne3UlNTZTabLX1++OEHq/1dma3wr33+PoNhamqqPD09rxkOXVxc5OLiUiznBgAAAKB0KlLY+uCDD264vXfv3gXaj2EYeuaZZ/T5559r8+bNCgkJsdreqFEjOTk5acOGDerataskKTExUUlJSQoLC5MkhYWFacqUKUpLS5Ovr68kKTY2Vp6enqpVq5alzzfffGO179jYWMs+AAAAAKC4FSlsDRs2zGo9NzdXFy5ckLOzs9zd3QsctqKjo7Vs2TJ9+eWXKleunOUdq/Lly8vNzU3ly5fXgAEDNHLkSFWsWFGenp565plnFBYWpqZNm0r6c7KOWrVqqVevXpoxY4ZSUlL04osvKjo62nJ3avDgwXr99dc1ZswY9e/fXxs3btSKFSu0atWqopw+AAAAANxUkb6zdebMGaslKytLiYmJat68eaEmyFiwYIEyMjIUHh6uSpUqWZbly5db+syaNUsdO3ZU165d1aJFC5nNZn322WeW7Q4ODlq5cqUcHBwUFhamnj17qnfv3po0aZKlT0hIiFatWqXY2FjVr19fMTExeuedd0rstO8AAAAA7nxFfmfr76pVq6bp06erZ8+eOnjwYIHGGIZx0z6urq6aP3++5s+ff90+wcHBVz0m+Hfh4eHas2dPgeoCAAAAgFtVpDtb1+Po6KiTJ08W5y4BAAAAoEQq0p2tr776ymrdMAwlJyfr9ddfV7NmzYqlMAAAAAAoyYoUth599FGrdZPJpHvuuUetW7dWTExMcdQFAAAAACVakcJWfn5+cdcBAAAAAHeVYn1nCwAAAADwpyLd2Ro5cmSB+86cObMohwAAAACAEq1IYWvPnj3as2ePcnNzVb16dUnSL7/8IgcHB91///2WfiaTqXiqBAAAAIASpkhhq1OnTipXrpzef/99VahQQdKfHzru16+fHnroIY0aNapYi0TxSkhIsGl/AAAAAEUMWzExMVq3bp0laElShQoV9Morr6ht27aErTtUXtYZyWRSz5497V0KAAAAcNcrUtjKzMzUH3/8cVX7H3/8oXPnzt1yUbCN/OwsyTDk3XGUnLwDCzzu4tFdyvh2iQ0rAwAAAO4+RQpbjz32mPr166eYmBg9+OCDkqQdO3Zo9OjR6tKlS7EWiOLn5B0oF3Nogfvnnjphw2oAAACAu1ORwtbChQv13HPP6amnnlJubu6fO3J01IABA/Taa68Va4EAAAAAUBIVKWy5u7vrjTfe0GuvvaYjR45IkqpWrSoPD49iLQ4AAAAASqpb+qhxcnKykpOTVa1aNXl4eMgwjOKqCwAAAABKtCKFrVOnTqlNmza677771KFDByUnJ0uSBgwYwEyEAAAAAKAihq0RI0bIyclJSUlJcnd3t7Q/+eSTWrNmTbEVBwAAAAAlVZHe2Vq3bp3Wrl2rgIAAq/Zq1arp+PHjxVIYAAAAAJRkRbqzdf78eas7WlecPn1aLi4ut1wUAAAAAJR0RQpbDz30kD744APLuslkUn5+vmbMmKFWrVoVW3EAAAAAUFIV6THCGTNmqE2bNtq1a5dycnI0ZswY7d+/X6dPn9Z3331X3DUCAAAAQIlTpDtbderU0S+//KLmzZurc+fOOn/+vLp06aI9e/aoatWqxV0jAAAAAJQ4hb6zlZubq3bt2mnhwoV64YUXbFETAAAAAJR4hb6z5eTkpL1799qiFgAAAAC4axTpMcKePXvq3XffLe5aAAAAAOCuUaQJMi5fvqz33ntP69evV6NGjeTh4WG1febMmcVSHAAAAACUVIUKW0ePHlWVKlX0888/6/7775ck/fLLL1Z9TCZT8VUHAAAAACVUocJWtWrVlJycrE2bNkmSnnzySc2dO1d+fn42KQ4AAAAASqpCvbNlGIbV+urVq3X+/PliLQgAAAAA7gZFmiDjir+Hr8LaunWrOnXqJH9/f5lMJn3xxRdW2/v27SuTyWS1tGvXzqrP6dOn1aNHD3l6esrLy0sDBgxQVlaWVZ+9e/fqoYcekqurqwIDAzVjxoxbqhsAAAAAbqZQjxFeCTx/byuq8+fPq379+urfv7+6dOlyzT7t2rXTokWLLOsuLi5W23v06KHk5GTFxsYqNzdX/fr106BBg7Rs2TJJUmZmptq2bauIiAgtXLhQ+/btU//+/eXl5aVBgwYVuXbAXhISEoo0zsfHR0FBQcVcDQAAAK6nUGHLMAz17dvXEnguXbqkwYMHXzUb4WeffVag/bVv317t27e/YR8XFxeZzeZrbktISNCaNWu0c+dONW7cWJI0b948dejQQf/973/l7++vpUuXKicnR++9956cnZ1Vu3ZtxcfHa+bMmYQtlCh5WWckk0k9e/Ys0nhXN3clHkwgcAEAANwmhQpbffr0sVov6j/6CmPz5s3y9fVVhQoV1Lp1a73yyivy9vaWJMXFxcnLy8sStCQpIiJCZcqU0Y4dO/TYY48pLi5OLVq0kLOzs6VPZGSkXn31VZ05c0YVKlS46pjZ2dnKzs62rGdmZtrwDIGCyc/OkgxD3h1Hyck7sFBjc0+d0KmVMUpPTydsAQAA3CaFClt/fZzvdmjXrp26dOmikJAQHTlyRP/5z3/Uvn17xcXFycHBQSkpKfL19bUa4+joqIoVKyolJUWSlJKSopCQEKs+V2ZPTElJuWbYmjZtml5++WUbnRVwa5y8A+ViDrV3GQAAALiJIn3U+Hbp1q2b5c9169ZVvXr1VLVqVW3evFlt2rSx2XHHjRunkSNHWtYzMzMVGFi4OwkAAAAASrdbmo3wdrv33nvl4+Ojw4cPS5LMZrPS0tKs+ly+fFmnT5+2vOdlNpuVmppq1efK+vXeBXNxcZGnp6fVAgAAAACFUaLC1m+//aZTp06pUqVKkqSwsDCdPXtWu3fvtvTZuHGj8vPz1aRJE0ufrVu3Kjc319InNjZW1atXv+YjhAAAAABQHOwatrKyshQfH6/4+HhJ0rFjxxQfH6+kpCRlZWVp9OjR2r59u3799Vdt2LBBnTt3VmhoqCIjIyVJNWvWVLt27fT000/rhx9+0HfffaehQ4eqW7du8vf3lyQ99dRTcnZ21oABA7R//34tX75cc+bMsXpMEAAAAACKm13D1q5du9SwYUM1bNhQkjRy5Eg1bNhQ48ePl4ODg/bu3atHHnlE9913nwYMGKBGjRrp22+/tfrW1tKlS1WjRg21adNGHTp0UPPmzfXWW29ZtpcvX17r1q3TsWPH1KhRI40aNUrjx49n2ncAAAAANmXXCTLCw8NlGMZ1t69du/am+6hYsaLlA8bXU69ePX377beFrg8AAAAAiqpEvbMFAAAAACUFYQsAAAAAbICwBQAAAAA2QNgCAAAAABsgbAEAAACADRC2AAAAAMAGCFsAAAAAYAOELQAAAACwAcIWAAAAANgAYQsAAAAAbICwBQAAAAA2QNgCAAAAABsgbAEAAACADRC2AAAAAMAGCFsAAAAAYAOELQAAAACwAcIWAAAAANgAYQsAAAAAbICwBQAAAAA24GjvAgDcPgkJCYUe4+Pjo6CgIBtUAwAAcHcjbAGlQF7WGclkUs+ePQs91tXNXYkHEwhcAAAAhUTYAkqB/OwsyTDk3XGUnLwDCzwu99QJnVoZo/T0dMIWAABAIRG2gFLEyTtQLuZQe5cBAABQKjBBBgAAAADYAGELAAAAAGyAsAUAAAAANkDYAgAAAAAbIGwBAAAAgA3YNWxt3bpVnTp1kr+/v0wmk7744gur7YZhaPz48apUqZLc3NwUERGhQ4cOWfU5ffq0evToIU9PT3l5eWnAgAHKysqy6rN371499NBDcnV1VWBgoGbMmGHrUwMAAABQytk1bJ0/f17169fX/Pnzr7l9xowZmjt3rhYuXKgdO3bIw8NDkZGRunTpkqVPjx49tH//fsXGxmrlypXaunWrBg0aZNmemZmptm3bKjg4WLt379Zrr72miRMn6q233rL5+QEAAAAovez6na327durffv219xmGIZmz56tF198UZ07d5YkffDBB/Lz89MXX3yhbt26KSEhQWvWrNHOnTvVuHFjSdK8efPUoUMH/fe//5W/v7+WLl2qnJwcvffee3J2dlbt2rUVHx+vmTNnWoUyAAAAAChOd+w7W8eOHVNKSooiIiIsbeXLl1eTJk0UFxcnSYqLi5OXl5claElSRESEypQpox07dlj6tGjRQs7OzpY+kZGRSkxM1JkzZ6557OzsbGVmZlotAAAAAFAYd2zYSklJkST5+flZtfv5+Vm2paSkyNfX12q7o6OjKlasaNXnWvv46zH+btq0aSpfvrxlCQwMvPUTAgAAAFCq3LFhy57GjRunjIwMy3LixAl7lwQAAACghLljw5bZbJYkpaamWrWnpqZatpnNZqWlpVltv3z5sk6fPm3V51r7+Osx/s7FxUWenp5WCwAAAAAUxh0btkJCQmQ2m7VhwwZLW2Zmpnbs2KGwsDBJUlhYmM6ePavdu3db+mzcuFH5+flq0qSJpc/WrVuVm5tr6RMbG6vq1aurQoUKt+lsAAAAAJQ2dg1bWVlZio+PV3x8vKQ/J8WIj49XUlKSTCaThg8frldeeUVfffWV9u3bp969e8vf31+PPvqoJKlmzZpq166dnn76af3www/67rvvNHToUHXr1k3+/v6SpKeeekrOzs4aMGCA9u/fr+XLl2vOnDkaOXKknc4aAAAAQGlg16nfd+3apVatWlnWrwSgPn36aPHixRozZozOnz+vQYMG6ezZs2revLnWrFkjV1dXy5ilS5dq6NChatOmjcqUKaOuXbtq7ty5lu3ly5fXunXrFB0drUaNGsnHx0fjx49n2ncAAAAANmXXsBUeHi7DMK673WQyadKkSZo0adJ1+1SsWFHLli274XHq1aunb7/9tsh1AgAAAEBh3bHvbAEAAABASUbYAgAAAAAbIGwBAAAAgA0QtgAAAADABghbAAAAAGADhC0AAAAAsAG7Tv0OoGRISEgo9BgfHx8FBQXZoBoAAICSgbAF4Lryss5IJpN69uxZ6LGubu5KPJhA4AIAAKUWYQvAdeVnZ0mGIe+Oo+TkHVjgcbmnTujUyhilp6cTtgAAQKlF2AJwU07egXIxh9q7DAAAgBKFCTIAAAAAwAYIWwAAAABgA4QtAAAAALABwhYAAAAA2ABhCwAAAABsgLAFAAAAADZA2AIAAAAAGyBsAQAAAIAN8FFjADaTkJBQ6DE+Pj4KCgqyQTUAAAC3F2ELQLHLyzojmUzq2bNnoce6urkr8WACgQsAAJR4hC0AxS4/O0syDHl3HCUn78ACj8s9dUKnVsYoPT2dsAUAAEo8whYAm3HyDpSLOdTeZQAAANgFE2QAAAAAgA0QtgAAAADABghbAAAAAGADhC0AAAAAsAHCFgAAAADYAGELAAAAAGzgjg5bEydOlMlkslpq1Khh2X7p0iVFR0fL29tbZcuWVdeuXZWammq1j6SkJEVFRcnd3V2+vr4aPXq0Ll++fLtPBQAAAEApc8d/Z6t27dpav369Zd3R8f9KHjFihFatWqWPP/5Y5cuX19ChQ9WlSxd99913kqS8vDxFRUXJbDbr+++/V3Jysnr37i0nJydNnTr1tp8LAAAAgNLjjg9bjo6OMpvNV7VnZGTo3Xff1bJly9S6dWtJ0qJFi1SzZk1t375dTZs21bp163TgwAGtX79efn5+atCggSZPnqyxY8dq4sSJcnZ2vt2nAwAAAKCUuKMfI5SkQ4cOyd/fX/fee6969OihpKQkSdLu3buVm5uriIgIS98aNWooKChIcXFxkqS4uDjVrVtXfn5+lj6RkZHKzMzU/v37r3vM7OxsZWZmWi0AAAAAUBh3dNhq0qSJFi9erDVr1mjBggU6duyYHnroIZ07d04pKSlydnaWl5eX1Rg/Pz+lpKRIklJSUqyC1pXtV7Zdz7Rp01S+fHnLEhgYWLwnBgAAAOCud0c/Rti+fXvLn+vVq6cmTZooODhYK1askJubm82OO27cOI0cOdKynpmZSeACAAAAUCh39J2tv/Py8tJ9992nw4cPy2w2KycnR2fPnrXqk5qaannHy2w2XzU74ZX1a70HdoWLi4s8PT2tFgAAAAAojBIVtrKysnTkyBFVqlRJjRo1kpOTkzZs2GDZnpiYqKSkJIWFhUmSwsLCtG/fPqWlpVn6xMbGytPTU7Vq1brt9QMAAAAoPe7oxwife+45derUScHBwTp58qQmTJggBwcHde/eXeXLl9eAAQM0cuRIVaxYUZ6ennrmmWcUFhampk2bSpLatm2rWrVqqVevXpoxY4ZSUlL04osvKjo6Wi4uLnY+OwDXk5CQUOgxPj4+CgoKskE1AAAARXNHh63ffvtN3bt316lTp3TPPfeoefPm2r59u+655x5J0qxZs1SmTBl17dpV2dnZioyM1BtvvGEZ7+DgoJUrV2rIkCEKCwuTh4eH+vTpo0mTJtnrlADcQF7WGclkUs+ePQs91tXNXYkHEwhcAADgjnFHh62PPvrohttdXV01f/58zZ8//7p9goOD9c033xR3aQBsID87SzIMeXccJSfvgk9Kk3vqhE6tjFF6ejphCwAA3DHu6LAFoHRy8g6UiznU3mUAAADckhI1QQYAAAAAlBSELQAAAACwAcIWAAAAANgAYQsAAAAAbICwBQAAAAA2QNgCAAAAABsgbAEAAACADRC2AAAAAMAG+KgxgLtGQkJCocf4+PgoKCjIBtUAAIDSjrAFoMTLyzojmUzq2bNnoce6urkr8WACgQsAABQ7whaAEi8/O0syDHl3HCUn78ACj8s9dUKnVsYoPT2dsAUAAIodYQvAXcPJO1Au5lB7lwEAACCJCTIAAAAAwCYIWwAAAABgA4QtAAAAALABwhYAAAAA2AATZAAo9fg+FwAAsAXCFoBSi+9zAQAAWyJsASi1+D4XAACwJcIWgFKvqN/n4vFDAABwI4QtACgkHj8EAAAFQdgCgELi8UMAAFAQhC0AKKKiPn4IAABKB76zBQAAAAA2QNgCAAAAABsgbAEAAACADRC2AAAAAMAGStUEGfPnz9drr72mlJQU1a9fX/PmzdODDz5o77IAlDJF+T5Xdna2XFxcCj2O73oBAGA/pSZsLV++XCNHjtTChQvVpEkTzZ49W5GRkUpMTJSvr6+9ywNQCtzK97lkKiMZ+YUexne9AACwn1ITtmbOnKmnn35a/fr1kyQtXLhQq1at0nvvvafnn3/eztUBKA2K+n2ui0d3KePbJUX+rte3336rmjVrFqrWot5Ju5WxJeUuXFJSktLT0ws97m7/XUqSov4d3u6/i5JyrZWU3xOwh1IRtnJycrR7926NGzfO0lamTBlFREQoLi7uqv7Z2dnKzs62rGdkZEiSMjMzbV9sAWRlZUmSslMOKz/nUoHH5Z46wbhSOM4ex2Tcjcfl52YXapxxOadI4y6f+/MfP0W6kyaTJKMI44o+1tnFVUv+94H8/PwKNa5MmTLKzy/8Xb+ijEtNTVXPXr2Vk124/w3+6e79Xewxrqhjb+Xv8Hb+XZSUa62k/J63Ms4ex2TctZnNZpnN5kKPK25XMoFh3Px/ZyajIL1KuJMnT6py5cr6/vvvFRYWZmkfM2aMtmzZoh07dlj1nzhxol5++eXbXSYAAACAEuLEiRMKCAi4YZ9ScWersMaNG6eRI0da1vPz83X8+HE1aNBAJ06ckKenpx2rw50qMzNTgYGBXCO4Lq4R3AzXCG6GawQ3wvVxexiGoXPnzsnf3/+mfUtF2PLx8ZGDg4NSU1Ot2lNTU695K9LFxeWqZ53LlPlzlnxPT08uXtwQ1whuhmsEN8M1gpvhGsGNcH3YXvny5QvUr1R8Z8vZ2VmNGjXShg0bLG35+fnasGGD1WOFAAAAAFBcSsWdLUkaOXKk+vTpo8aNG+vBBx/U7Nmzdf78ecvshAAAAABQnEpN2HryySf1xx9/aPz48UpJSVGDBg20Zs2aAs+A4+LiogkTJhR5KmTc/bhGcDNcI7gZrhHcDNcIboTr485TKmYjBAAAAIDbrVS8swUAAAAAtxthCwAAAABsgLAFAAAAADZA2AIAAAAAGyBsFdD8+fNVpUoVubq6qkmTJvrhhx/sXRLsYNq0aXrggQdUrlw5+fr66tFHH1ViYqJVn0uXLik6Olre3t4qW7asunbtetUHtVF6TJ8+XSaTScOHD7e0cY3g999/V8+ePeXt7S03NzfVrVtXu3btsmw3DEPjx49XpUqV5ObmpoiICB06dMiOFeN2ysvL00svvaSQkBC5ubmpatWqmjx5sv46pxnXSOmydetWderUSf7+/jKZTPriiy+sthfkejh9+rR69OghT09PeXl5acCAAcrKyrqNZ1E6EbYKYPny5Ro5cqQmTJigH3/8UfXr11dkZKTS0tLsXRpusy1btig6Olrbt29XbGyscnNz1bZtW50/f97SZ8SIEfr666/18ccfa8uWLTp58qS6dOlix6phLzt37tSbb76pevXqWbVzjZRuZ86cUbNmzeTk5KTVq1frwIEDiomJUYUKFSx9ZsyYoblz52rhwoXasWOHPDw8FBkZqUuXLtmxctwur776qhYsWKDXX39dCQkJevXVVzVjxgzNmzfP0odrpHQ5f/686tevr/nz519ze0Guhx49emj//v2KjY3VypUrtXXrVg0aNOh2nULpZeCmHnzwQSM6OtqynpeXZ/j7+xvTpk2zY1W4E6SlpRmSjC1bthiGYRhnz541nJycjI8//tjSJyEhwZBkxMXF2atM2MG5c+eMatWqGbGxsUbLli2NYcOGGYbBNQLDGDt2rNG8efPrbs/PzzfMZrPx2muvWdrOnj1ruLi4GB9++OHtKBF2FhUVZfTv39+qrUuXLkaPHj0Mw+AaKe0kGZ9//rllvSDXw4EDBwxJxs6dOy19Vq9ebZhMJuP333+/bbWXRtzZuomcnBzt3r1bERERlrYyZcooIiJCcXFxdqwMd4KMjAxJUsWKFSVJu3fvVm5urtX1UqNGDQUFBXG9lDLR0dGKioqyuhYkrhFIX331lRo3bqx//vOf8vX1VcOGDfX2229bth87dkwpKSlW10j58uXVpEkTrpFS4h//+Ic2bNigX375RZL0008/adu2bWrfvr0krhFYK8j1EBcXJy8vLzVu3NjSJyIiQmXKlNGOHTtue82liaO9C7jTpaenKy8vT35+flbtfn5+OnjwoJ2qwp0gPz9fw4cPV7NmzVSnTh1JUkpKipydneXl5WXV18/PTykpKXaoEvbw0Ucf6ccff9TOnTuv2sY1gqNHj2rBggUaOXKk/vOf/2jnzp169tln5ezsrD59+liug2v9d4drpHR4/vnnlZmZqRo1asjBwUF5eXmaMmWKevToIUlcI7BSkOshJSVFvr6+VtsdHR1VsWJFrhkbI2wBRRQdHa2ff/5Z27Zts3cpuIOcOHFCw4YNU2xsrFxdXe1dDu5A+fn5aty4saZOnSpJatiwoX7++WctXLhQffr0sXN1uBOsWLFCS5cu1bJly1S7dm3Fx8dr+PDh8vf35xoBShgeI7wJHx8fOTg4XDVTWGpqqsxms52qgr0NHTpUK1eu1KZNmxQQEGBpN5vNysnJ0dmzZ636c72UHrt371ZaWpruv/9+OTo6ytHRUVu2bNHcuXPl6OgoPz8/rpFSrlKlSqpVq5ZVW82aNZWUlCRJluuA/+6UXqNHj9bzzz+vbt26qW7duurVq5dGjBihadOmSeIagbWCXA9ms/mqid0uX76s06dPc83YGGHrJpydndWoUSNt2LDB0pafn68NGzYoLCzMjpXBHgzD0NChQ/X5559r48aNCgkJsdreqFEjOTk5WV0viYmJSkpK4nopJdq0aaN9+/YpPj7esjRu3Fg9evSw/JlrpHRr1qzZVZ+M+OWXXxQcHCxJCgkJkdlstrpGMjMztWPHDq6RUuLChQsqU8b6n2gODg7Kz8+XxDUCawW5HsLCwnT27Fnt3r3b0mfjxo3Kz89XkyZNbnvNpYq9Z+goCT766CPDxcXFWLx4sXHgwAFj0KBBhpeXl5GSkmLv0nCbDRkyxChfvryxefNmIzk52bJcuHDB0mfw4MFGUFCQsXHjRmPXrl1GWFiYERYWZseqYW9/nY3QMLhGSrsffvjBcHR0NKZMmWIcOnTIWLp0qeHu7m4sWbLE0mf69OmGl5eX8eWXXxp79+41OnfubISEhBgXL160Y+W4Xfr06WNUrlzZWLlypXHs2DHjs88+M3x8fIwxY8ZY+nCNlC7nzp0z9uzZY+zZs8eQZMycOdPYs2ePcfz4ccMwCnY9tGvXzmjYsKGxY8cOY9u2bUa1atWM7t272+uUSg3CVgHNmzfPCAoKMpydnY0HH3zQ2L59u71Lgh1IuuayaNEiS5+LFy8a//73v40KFSoY7u7uxmOPPWYkJyfbr2jY3d/DFtcIvv76a6NOnTqGi4uLUaNGDeOtt96y2p6fn2+89NJLhp+fn+Hi4mK0adPGSExMtFO1uN0yMzONYcOGGUFBQYarq6tx7733Gi+88IKRnZ1t6cM1Urps2rTpmv/+6NOnj2EYBbseTp06ZXTv3t0oW7as4enpafTr1884d+6cHc6mdDEZxl8+Rw4AAAAAKBa8swUAAAAANkDYAgAAAAAbIGwBAAAAgA0QtgAAAADABghbAAAAAGADhC0AAAAAsAHCFgAAAADYAGELAAAAAGyAsAUAKNF+/fVXmUwmxcfH27sUi4MHD6pp06ZydXVVgwYN7F3ONYWHh2v48OH2LgMA7mqELQDALenbt69MJpOmT59u1f7FF1/IZDLZqSr7mjBhgjw8PJSYmKgNGzZctX3hwoUqV66cLl++bGnLysqSk5OTwsPDrfpu3rxZJpNJR44csXXZAIBiRtgCANwyV1dXvfrqqzpz5oy9Syk2OTk5RR575MgRNW/eXMHBwfL29r5qe6tWrZSVlaVdu3ZZ2r799luZzWbt2LFDly5dsrRv2rRJQUFBqlq1aqHrMAzDKtABAG4vwhYA4JZFRETIbDZr2rRp1+0zceLEqx6pmz17tqpUqWJZ79u3rx599FFNnTpVfn5+8vLy0qRJk3T58mWNHj1aFStWVEBAgBYtWnTV/g8ePKh//OMfcnV1VZ06dbRlyxar7T///LPat2+vsmXLys/PT7169VJ6erple3h4uIYOHarhw4fLx8dHkZGR1zyP/Px8TZo0SQEBAXJxcVGDBg20Zs0ay3aTyaTdu3dr0qRJMplMmjhx4lX7qF69uipVqqTNmzdb2jZv3qzOnTsrJCRE27dvt2pv1aqVJCk7O1vPPvusfH195erqqubNm2vnzp1WfU0mk1avXq1GjRrJxcVF27Zt0/nz59W7d2+VLVtWlSpVUkxMzFU1vfHGG6pWrZpcXV3l5+enxx9//JrnDwAoOMIWAOCWOTg4aOrUqZo3b55+++23W9rXxo0bdfLkSW3dulUzZ87UhAkT1LFjR1WoUEE7duzQ4MGD9a9//euq44wePVqjRo3Snj17FBYWpk6dOunUqVOSpLNnz6p169Zq2LChdu3apTVr1ig1NVVPPPGE1T7ef/99OTs767vvvtPChQuvWd+cOXMUExOj//73v9q7d68iIyP1yCOP6NChQ5Kk5ORk1a5dW6NGjVJycrKee+65a+6nVatW2rRpk2V906ZNCg8PV8uWLS3tFy9e1I4dOyxha8yYMfr000/1/vvv68cff1RoaKgiIyN1+vRpq30///zzmj59uhISElSvXj2NHj1aW7Zs0Zdffql169Zp8+bN+vHHHy39d+3apWeffVaTJk1SYmKi1qxZoxYtWtz07woAcBMGAAC3oE+fPkbnzp0NwzCMpk2bGv379zcMwzA+//xz46//mZkwYYJRv359q7GzZs0ygoODrfYVHBxs5OXlWdqqV69uPPTQQ5b1y5cvGx4eHsaHH35oGIZhHDt2zJBkTJ8+3dInNzfXCAgIMF599VXDMAxj8uTJRtu2ba2OfeLECUOSkZiYaBiGYbRs2dJo2LDhTc/X39/fmDJlilXbAw88YPz73/+2rNevX9+YMGHCDffz9ttvGx4eHkZubq6RmZlpODo6GmlpacayZcuMFi1aGIZhGBs2bDAkGcePHzeysrIMJycnY+nSpZZ95OTkGP7+/saMGTMMwzCMTZs2GZKML774wtLn3LlzhrOzs7FixQpL26lTpww3Nzdj2LBhhmEYxqeffmp4enoamZmZNz1/AEDBcWcLAFBsXn31Vb3//vtKSEgo8j5q166tMmX+7z9Pfn5+qlu3rmXdwcFB3t7eSktLsxoXFhZm+bOjo6MaN25sqeOnn37Spk2bVLZsWctSo0YNSbKaeKJRo0Y3rC0zM1MnT55Us2bNrNqbNWtW6HMODw/X+fPntXPnTn377be67777dM8996hly5aW97Y2b96se++9V0FBQTpy5Ihyc3Otju3k5KQHH3zwqmM3btzY8ucjR44oJydHTZo0sbRVrFhR1atXt6w//PDDCg4O1r333qtevXpp6dKlunDhQqHOBwBwNcIWAKDYtGjRQpGRkRo3btxV28qUKSPDMKzacnNzr+rn5ORktW4yma7Zlp+fX+C6srKy1KlTJ8XHx1sthw4dsnpczsPDo8D7vFWhoaEKCAjQpk2btGnTJrVs2VKS5O/vr8DAQH3//ffatGmTWrduXeh9F/Y8ypUrpx9//FEffvihKlWqpPHjx6t+/fo6e/ZsoY8NAPg/hC0AQLGaPn26vv76a8XFxVm133PPPUpJSbEKXMX5bay/Tipx+fJl7d69WzVr1pQk3X///dq/f7+qVKmi0NBQq6UwwcTT01P+/v767rvvrNq/++471apVq9A1t2rVSps3b9bmzZutpnxv0aKFVq9erR9++MHyvlbVqlUt75NdkZubq507d97w2FWrVpWTk5N27NhhaTtz5ox++eUXq36Ojo6KiIjQjBkztHfvXv3666/auHFjoc8JAPB/HO1dAADg7lK3bl316NFDc+fOtWoPDw/XH3/8oRkzZujxxx/XmjVrtHr1anl6ehbLcefPn69q1aqpZs2amjVrls6cOaP+/ftLkqKjo/X222+re/fuGjNmjCpWrKjDhw/ro48+0jvvvCMHB4cCH2f06NGaMGGCqlatqgYNGmjRokWKj4/X0qVLC11zq1atFB0drdzcXMudLUlq2bKlhg4dqpycHEvY8vDw0JAhQyyzMgYFBWnGjBm6cOGCBgwYcN1jlC1bVgMGDNDo0aPl7e0tX19fvfDCC1aPaq5cuVJHjx5VixYtVKFCBX3zzTfKz8+3etQQAFB4hC0AQLGbNGmSli9fbtVWs2ZNvfHGG5o6daomT56srl276rnnntNbb71VLMecPn26pk+frvj4eIWGhuqrr76Sj4+PJFnuRo0dO1Zt27ZVdna2goOD1a5dO6vQURDPPvusMjIyNGrUKKWlpalWrVr66quvVK1atULX3KpVK128eFE1atSQn5+fpb1ly5Y6d+6cZYr4v55jfn6+evXqpXPnzqlx48Zau3atKlSocMPjvPbaa5ZHKcuVK6dRo0YpIyPDst3Ly0ufffaZJk6cqEuXLqlatWr68MMPVbt27UKfEwDg/5iMvz9ADwAAAAC4ZbyzBQAAAAA2QNgCAAAAABsgbAEAAACADRC2AAAAAMAGCFsAAAAAYAOELQAAAACwAcIWAAAAANgAYQsAAAAAbICwBQAAAAA2QNgCAAAAABsgbAEAAACADfw/AUGVcbgnSEcAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Data"
      ],
      "metadata": {
        "id": "hAsQlQaUBOaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "MAX_WORDS = 10000        # Vocabulary size\n",
        "MAX_SEQUENCE_LENGTH = 200  # Max number of words per text\n",
        "EMBEDDING_DIM = 128      # Word embedding dimension\n",
        "\n",
        "# Prepare texts and labels\n",
        "texts = df['text'].astype(str).tolist()\n",
        "labels = df['label'].values\n",
        "\n",
        "# Split data\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    texts, labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=labels\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    stratify=y_temp\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Validation samples: {len(X_val)}\")\n",
        "print(f\"Test samples: {len(X_test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3l4U33-BJ8V",
        "outputId": "291e583a-7385-457e-d19d-2dcb8f29ec66"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 24000\n",
            "Validation samples: 3000\n",
            "Test samples: 3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization and Padding"
      ],
      "metadata": {
        "id": "JNckjMspBlMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tokenizer\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Convert texts to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Pad sequences\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
        "X_val_pad = pad_sequences(X_val_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "print(f\"Vocabulary size: {len(tokenizer.word_index)}\")\n",
        "print(f\"Training data shape: {X_train_pad.shape}\")\n",
        "\n",
        "# Get number of classes\n",
        "num_classes = len(np.unique(labels))\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l07ZCdmKBioK",
        "outputId": "8a618b73-6ca2-4359-cc48-2f89980aa706"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 30903\n",
            "Training data shape: (24000, 200)\n",
            "Number of classes: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Custom Attention Layer"
      ],
      "metadata": {
        "id": "N0vZ_5omBswk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, backend as K\n",
        "\n",
        "class AttentionLayer(layers.Layer):\n",
        "    \"\"\"\n",
        "    Custom Attention Layer\n",
        "    Learns to focus on important parts of the text\n",
        "    \"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Attention weight matrix\n",
        "        self.W = self.add_weight(\n",
        "            name='attention_weight',\n",
        "            shape=(input_shape[-1], input_shape[-1]),\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=True\n",
        "        )\n",
        "        # Attention bias\n",
        "        self.b = self.add_weight(\n",
        "            name='attention_bias',\n",
        "            shape=(input_shape[-1],),\n",
        "            initializer='zeros',\n",
        "            trainable=True\n",
        "        )\n",
        "        # Attention vector\n",
        "        self.u = self.add_weight(\n",
        "            name='attention_vector',\n",
        "            shape=(input_shape[-1],),\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=True\n",
        "        )\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        # x shape: (batch_size, time_steps, features)\n",
        "\n",
        "        # Compute attention scores\n",
        "        uit = K.tanh(K.dot(x, self.W) + self.b)  # (batch_size, time_steps, features)\n",
        "\n",
        "        # Alternative calculation for ait using element-wise multiplication and summation\n",
        "        # Expand dimensions of self.u to (1, 1, features) for broadcasting\n",
        "        u_expanded = K.expand_dims(K.expand_dims(self.u, axis=0), axis=0) # Shape (1, 1, features)\n",
        "        # Element-wise multiplication\n",
        "        weighted_uit = uit * u_expanded # Shape (batch_size, time_steps, features)\n",
        "        # Sum over the last dimension to get attention scores\n",
        "        ait = K.sum(weighted_uit, axis=-1) # Shape (batch_size, time_steps)\n",
        "\n",
        "\n",
        "        # Apply softmax to get attention weights\n",
        "        attention_weights = K.softmax(ait, axis=1)  # (batch_size, time_steps)\n",
        "        attention_weights = K.expand_dims(attention_weights, axis=-1)  # (batch_size, time_steps, 1)\n",
        "\n",
        "        # Apply attention weights to input\n",
        "        weighted_input = x * attention_weights  # (batch_size, time_steps, features)\n",
        "\n",
        "        # Sum over time steps\n",
        "        output = K.sum(weighted_input, axis=1)  # (batch_size, features)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], input_shape[-1])\n",
        "\n",
        "    def get_config(self):\n",
        "        return super(AttentionLayer, self).get_config()"
      ],
      "metadata": {
        "id": "VYYUskRBBqIF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Multi-Channel CNN with Attention"
      ],
      "metadata": {
        "id": "MdDGtBa7B2Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_multichannel_cnn_with_attention(vocab_size, embedding_dim, max_length, num_classes):\n",
        "    \"\"\"\n",
        "    Multi-Channel CNN with Attention Architecture:\n",
        "    - Embedding layer\n",
        "    - Multiple parallel CNN channels with different filter sizes\n",
        "    - Attention mechanism on CNN outputs\n",
        "    - Dense layers for classification\n",
        "    \"\"\"\n",
        "\n",
        "    # Input\n",
        "    input_layer = layers.Input(shape=(max_length,), name='input')\n",
        "\n",
        "    # Embedding layer\n",
        "    embedding = layers.Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_dim,\n",
        "        input_length=max_length,\n",
        "        name='embedding'\n",
        "    )(input_layer)\n",
        "\n",
        "    # Dropout after embedding\n",
        "    embedding = layers.Dropout(0.3, name='embedding_dropout')(embedding)\n",
        "\n",
        "    # ============= MULTI-CHANNEL CNN =============\n",
        "    # Different kernel sizes capture different n-gram patterns\n",
        "\n",
        "    conv_outputs = []\n",
        "    filter_sizes = [2, 3, 4, 5]  # Different n-gram sizes\n",
        "    num_filters = 128\n",
        "\n",
        "    for i, filter_size in enumerate(filter_sizes):\n",
        "        # Convolutional layer\n",
        "        conv = layers.Conv1D(\n",
        "            filters=num_filters,\n",
        "            kernel_size=filter_size,\n",
        "            activation='relu',\n",
        "            padding='same',\n",
        "            name=f'conv_{filter_size}'\n",
        "        )(embedding)\n",
        "\n",
        "        # Batch normalization\n",
        "        conv = layers.BatchNormalization(name=f'bn_{filter_size}')(conv)\n",
        "\n",
        "        # Apply attention to this channel\n",
        "        attention_output = AttentionLayer(name=f'attention_{filter_size}')(conv)\n",
        "\n",
        "        conv_outputs.append(attention_output)\n",
        "\n",
        "    # Concatenate all channels\n",
        "    merged = layers.Concatenate(name='concat')(conv_outputs)\n",
        "\n",
        "    # ============= DENSE LAYERS =============\n",
        "\n",
        "    # First dense layer\n",
        "    dense1 = layers.Dense(512, activation='relu', name='dense1')(merged)\n",
        "    dense1 = layers.BatchNormalization(name='bn_dense1')(dense1)\n",
        "    dense1 = layers.Dropout(0.5, name='dropout1')(dense1)\n",
        "\n",
        "    # Second dense layer\n",
        "    dense2 = layers.Dense(256, activation='relu', name='dense2')(dense1)\n",
        "    dense2 = layers.BatchNormalization(name='bn_dense2')(dense2)\n",
        "    dense2 = layers.Dropout(0.4, name='dropout2')(dense2)\n",
        "\n",
        "    # Third dense layer\n",
        "    dense3 = layers.Dense(128, activation='relu', name='dense3')(dense2)\n",
        "    dense3 = layers.Dropout(0.3, name='dropout3')(dense3)\n",
        "\n",
        "    # Output layer\n",
        "    output = layers.Dense(num_classes, activation='softmax', name='output')(dense3)\n",
        "\n",
        "    # Create model\n",
        "    model = models.Model(inputs=input_layer, outputs=output, name='MultiChannel_CNN_Attention')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build the model\n",
        "model = build_multichannel_cnn_with_attention(\n",
        "    vocab_size=MAX_WORDS,\n",
        "    embedding_dim=EMBEDDING_DIM,\n",
        "    max_length=MAX_SEQUENCE_LENGTH,\n",
        "    num_classes=num_classes\n",
        ")\n",
        "\n",
        "# Display model architecture\n",
        "model.summary()\n",
        "\n",
        "# Visualize model architecture (optional)\n",
        "try:\n",
        "    keras.utils.plot_model(\n",
        "        model,\n",
        "        to_file='model_architecture.png',\n",
        "        show_shapes=True,\n",
        "        show_layer_names=True,\n",
        "        rankdir='TB',\n",
        "        dpi=96\n",
        "    )\n",
        "    print(\"✅ Model architecture saved as 'model_architecture.png'\")\n",
        "except:\n",
        "    print(\"⚠️ Could not generate model visualization\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0fau7gj6B4s1",
        "outputId": "5dcf0b60-3e25-4ce0-84e7-4b41b33343d4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"MultiChannel_CNN_Attention\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MultiChannel_CNN_Attention\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │  \u001b[38;5;34m1,280,000\u001b[0m │ input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_dropout   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv_2 (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m32,896\u001b[0m │ embedding_dropou… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv_3 (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m49,280\u001b[0m │ embedding_dropou… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv_4 (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m65,664\u001b[0m │ embedding_dropou… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv_5 (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m82,048\u001b[0m │ embedding_dropou… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bn_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m512\u001b[0m │ conv_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bn_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m512\u001b[0m │ conv_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bn_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m512\u001b[0m │ conv_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bn_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m512\u001b[0m │ conv_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,640\u001b[0m │ bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,640\u001b[0m │ bn_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,640\u001b[0m │ bn_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,640\u001b[0m │ bn_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concat              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ attention_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ attention_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ attention_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense1 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ concat[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bn_dense1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout1 (\u001b[38;5;33mDropout\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bn_dense1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense2 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ dropout1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bn_dense2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout2 (\u001b[38;5;33mDropout\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bn_dense2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense3 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout3 (\u001b[38;5;33mDropout\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        │      \u001b[38;5;34m1,935\u001b[0m │ dropout3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_dropout   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ embedding_dropou… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │ embedding_dropou… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ embedding_dropou… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span> │ embedding_dropou… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bn_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bn_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bn_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bn_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ bn_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ bn_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ bn_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concat              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ attention_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ attention_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bn_dense1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bn_dense1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dropout1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bn_dense2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bn_dense2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,935</span> │ dropout3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,010,383\u001b[0m (7.67 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,010,383</span> (7.67 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,007,823\u001b[0m (7.66 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,007,823</span> (7.66 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,560\u001b[0m (10.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,560</span> (10.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model architecture saved as 'model_architecture.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the Model"
      ],
      "metadata": {
        "id": "j2jfYXjVCEJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compile model with Adam optimizer\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"✅ Model compiled successfully!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxG5tGl7CGz5",
        "outputId": "87201346-0651-4397-b366-6fc5644936ba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model compiled successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup Callbacks"
      ],
      "metadata": {
        "id": "SuBXtfjoCPtk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'best_multichannel_cnn_attention.h5',\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    mode='max',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=0.00001,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "callbacks = [early_stopping, model_checkpoint, reduce_lr]\n",
        "\n",
        "print(\"✅ Callbacks configured!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF1umr_hCOHQ",
        "outputId": "174f2884-927c-4adf-f527-ca437885c5a7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Callbacks configured!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the Model"
      ],
      "metadata": {
        "id": "YN1ZPQpGCYpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "print(\"🚀 Starting training...\\n\")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    epochs=25,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n✅ Training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "m9SR70aTCV-n",
        "outputId": "cf5b0cec-dce0-4826-deba-c26634ebd227"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Starting training...\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "Exception encountered when calling AttentionLayer.call().\n\n\u001b[1mpop index out of range\u001b[0m\n\nArguments received by AttentionLayer.call():\n  • x=tf.Tensor(shape=(64, 200, 128), dtype=float32)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1308118698.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🚀 Starting training...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mX_train_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4039775929.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Compute attention scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0muit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, time_steps, features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m                  \u001b[0;31m# (batch_size, time_steps)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Apply softmax to get attention weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Exception encountered when calling AttentionLayer.call().\n\n\u001b[1mpop index out of range\u001b[0m\n\nArguments received by AttentionLayer.call():\n  • x=tf.Tensor(shape=(64, 200, 128), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c21b8e6",
        "outputId": "d5a69131-f3fc-4c2b-a665-acd57db1d165"
      },
      "source": [
        "# Train the model again\n",
        "print(\"🚀 Starting training with modified model...\\n\")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    epochs=25,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n✅ Training complete!\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Starting training with modified model...\n",
            "\n",
            "Epoch 1/25\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672ms/step - accuracy: 0.7686 - loss: 0.7920\n",
            "Epoch 1: val_accuracy did not improve from 0.61500\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 693ms/step - accuracy: 0.7686 - loss: 0.7920 - val_accuracy: 0.6117 - val_loss: 1.5100 - learning_rate: 5.0000e-04\n",
            "Epoch 2/25\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645ms/step - accuracy: 0.8330 - loss: 0.5734\n",
            "Epoch 2: val_accuracy did not improve from 0.61500\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 673ms/step - accuracy: 0.8330 - loss: 0.5734 - val_accuracy: 0.6060 - val_loss: 1.6318 - learning_rate: 5.0000e-04\n",
            "Epoch 3/25\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649ms/step - accuracy: 0.8645 - loss: 0.4557\n",
            "Epoch 3: val_accuracy did not improve from 0.61500\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 677ms/step - accuracy: 0.8644 - loss: 0.4558 - val_accuracy: 0.6120 - val_loss: 1.6679 - learning_rate: 5.0000e-04\n",
            "Epoch 4/25\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645ms/step - accuracy: 0.8952 - loss: 0.3512\n",
            "Epoch 4: val_accuracy did not improve from 0.61500\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 672ms/step - accuracy: 0.8952 - loss: 0.3513 - val_accuracy: 0.6040 - val_loss: 1.8539 - learning_rate: 5.0000e-04\n",
            "Epoch 5/25\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650ms/step - accuracy: 0.9180 - loss: 0.2688\n",
            "Epoch 5: val_accuracy did not improve from 0.61500\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 678ms/step - accuracy: 0.9180 - loss: 0.2688 - val_accuracy: 0.6000 - val_loss: 2.0496 - learning_rate: 2.5000e-04\n",
            "Epoch 6/25\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732ms/step - accuracy: 0.9391 - loss: 0.2032\n",
            "Epoch 6: val_accuracy did not improve from 0.61500\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 759ms/step - accuracy: 0.9391 - loss: 0.2032 - val_accuracy: 0.6080 - val_loss: 2.1496 - learning_rate: 2.5000e-04\n",
            "Epoch 6: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "\n",
            "✅ Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "ea7c1455",
        "outputId": "748c5404-4f30-4e8c-aaf3-6674b44a72e3"
      },
      "source": [
        "# Train the model again\n",
        "print(\"🚀 Starting training with modified model...\\n\")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    epochs=25,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n✅ Training complete!\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Starting training with modified model...\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "Exception encountered when calling AttentionLayer.call().\n\n\u001b[1mpop index out of range\u001b[0m\n\nArguments received by AttentionLayer.call():\n  • x=tf.Tensor(shape=(64, 200, 128), dtype=float32)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-732014337.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🚀 Starting training with modified model...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mX_train_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4039775929.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Compute attention scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0muit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, time_steps, features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m                  \u001b[0;31m# (batch_size, time_steps)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Apply softmax to get attention weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Exception encountered when calling AttentionLayer.call().\n\n\u001b[1mpop index out of range\u001b[0m\n\nArguments received by AttentionLayer.call():\n  • x=tf.Tensor(shape=(64, 200, 128), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Training History"
      ],
      "metadata": {
        "id": "HGhzwZHPammV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Accuracy\n",
        "axes[0].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
        "axes[0].plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
        "axes[0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
        "axes[0].legend(fontsize=10)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Loss\n",
        "axes[1].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
        "axes[1].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
        "axes[1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "axes[1].set_ylabel('Loss', fontsize=12)\n",
        "axes[1].legend(fontsize=10)\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✅ Training history saved as 'training_history.png'\")\n"
      ],
      "metadata": {
        "id": "hpBJGmK-Cblf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate on Test Set"
      ],
      "metadata": {
        "id": "djvhMLr3a7px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best model\n",
        "model.load_weights('best_multichannel_cnn_attention.h5')\n",
        "\n",
        "# Predict on test set\n",
        "print(\"📊 Evaluating on test set...\\n\")\n",
        "test_loss, test_accuracy = model.evaluate(X_test_pad, y_test, verbose=0)\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "\n",
        "# Get predictions\n",
        "y_pred_probs = model.predict(X_test_pad, verbose=0)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Classification report\n",
        "print(\"\\n📋 Detailed Classification Report:\")\n",
        "target_names = [f\"Class {i}\" for i in range(num_classes)]\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "# Overall metrics\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"OVERALL METRICS:\")\n",
        "print(f\"{'='*50}\")\n",
        "print(f\"Accuracy:  {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "print(f\"Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
        "print(f\"Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
        "print(f\"F1-Score:  {f1:.4f} ({f1*100:.2f}%)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnjXA2lKa8Ye",
        "outputId": "eebf049a-9b6e-41ca-ee4e-51611dea82e5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Evaluating on test set...\n",
            "\n",
            "Test Loss: 1.3268\n",
            "Test Accuracy: 0.6053 (60.53%)\n",
            "\n",
            "📋 Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.57      0.49      0.53       200\n",
            "     Class 1       0.65      0.44      0.53       200\n",
            "     Class 2       0.69      0.72      0.71       200\n",
            "     Class 3       0.41      0.49      0.45       200\n",
            "     Class 4       0.55      0.67      0.60       200\n",
            "     Class 5       0.62      0.82      0.71       200\n",
            "     Class 6       0.49      0.49      0.49       200\n",
            "     Class 7       0.49      0.65      0.56       200\n",
            "     Class 8       0.69      0.53      0.60       200\n",
            "     Class 9       0.83      0.76      0.79       200\n",
            "    Class 10       0.80      0.66      0.72       200\n",
            "    Class 11       0.62      0.69      0.66       200\n",
            "    Class 12       0.53      0.58      0.56       200\n",
            "    Class 13       0.60      0.44      0.51       200\n",
            "    Class 14       0.69      0.65      0.66       200\n",
            "\n",
            "    accuracy                           0.61      3000\n",
            "   macro avg       0.62      0.61      0.60      3000\n",
            "weighted avg       0.62      0.61      0.60      3000\n",
            "\n",
            "\n",
            "==================================================\n",
            "OVERALL METRICS:\n",
            "==================================================\n",
            "Accuracy:  0.6053 (60.53%)\n",
            "Precision: 0.6165 (61.65%)\n",
            "Recall:    0.6053 (60.53%)\n",
            "F1-Score:  0.6047 (60.47%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix"
      ],
      "metadata": {
        "id": "_JMyfPtwbCA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# Confusion matrix\n",
        "plt.figure(figsize=(14, 12))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    cmap='YlOrRd',\n",
        "    cbar=True,\n",
        "    square=True,\n",
        "    linewidths=0.5\n",
        ")\n",
        "plt.title('Confusion Matrix - Multi-Channel CNN with Attention', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✅ Confusion matrix saved as 'confusion_matrix.png'\")\n",
        "\n",
        "# Per-class accuracy\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"PER-CLASS ACCURACY:\")\n",
        "print(\"=\"*50)\n",
        "class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
        "for i, acc in enumerate(class_accuracy):\n",
        "    print(f\"Class {i:2d}: {acc:.4f} ({acc*100:.2f}%)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "f6c9qpgkbAya",
        "outputId": "a93fcfa8-858d-4c14-9be3-84c2ac9200bb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'python' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2362143096.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m sns.heatmap(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'python' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize Attention Weights"
      ],
      "metadata": {
        "id": "eGpXdqcsbKDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model that outputs attention weights\n",
        "def create_attention_model(trained_model):\n",
        "    \"\"\"\n",
        "    Creates a model that outputs attention weights for visualization\n",
        "    \"\"\"\n",
        "    attention_outputs = []\n",
        "    for layer in trained_model.layers:\n",
        "        if 'attention' in layer.name:\n",
        "            # Get the conv layer before this attention\n",
        "            conv_layer_name = layer.name.replace('attention', 'conv')\n",
        "            conv_output = trained_model.get_layer(conv_layer_name).output\n",
        "            attention_outputs.append(conv_output)\n",
        "\n",
        "    if attention_outputs:\n",
        "        attention_model = models.Model(\n",
        "            inputs=trained_model.input,\n",
        "            outputs=attention_outputs\n",
        "        )\n",
        "        return attention_model\n",
        "    return None\n",
        "\n",
        "# Get attention model\n",
        "attention_model = create_attention_model(model)\n",
        "\n",
        "if attention_model:\n",
        "    # Visualize attention for a sample\n",
        "    sample_idx = 0\n",
        "    sample_text = X_test[sample_idx]\n",
        "    sample_input = X_test_pad[sample_idx:sample_idx+1]\n",
        "\n",
        "    print(f\"Sample text: {sample_text[:200]}...\")\n",
        "    print(f\"True label: {y_test[sample_idx]}\")\n",
        "    print(f\"Predicted label: {y_pred[sample_idx]}\")\n",
        "\n",
        "    # Get attention outputs\n",
        "    attention_outputs = attention_model.predict(sample_input, verbose=0)\n",
        "\n",
        "    print(\"\\n✅ Attention mechanism is working!\")\n",
        "else:\n",
        "    print(\"⚠️ Could not create attention visualization model\")\n"
      ],
      "metadata": {
        "id": "i5I2AWt7bJOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Model and Preprocessing Objects"
      ],
      "metadata": {
        "id": "K9WKF3F8bQPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('multichannel_cnn_attention.h5')\n",
        "print(\"✅ Model saved as 'multichannel_cnn_attention.h5'\")\n",
        "\n",
        "# Save tokenizer\n",
        "with open('tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "print(\"✅ Tokenizer saved as 'tokenizer.pkl'\")\n",
        "\n",
        "# Save label mapping\n",
        "label_mapping = df[['category', 'label']].drop_duplicates().sort_values('label')\n",
        "with open('label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(label_mapping, f)\n",
        "print(\"✅ Label encoder saved as 'label_encoder.pkl'\")\n",
        "\n",
        "# Save config\n",
        "config = {\n",
        "    'MAX_WORDS': MAX_WORDS,\n",
        "    'MAX_SEQUENCE_LENGTH': MAX_SEQUENCE_LENGTH,\n",
        "    'EMBEDDING_DIM': EMBEDDING_DIM,\n",
        "    'num_classes': num_classes,\n",
        "    'filter_sizes': [2, 3, 4, 5],\n",
        "    'num_filters': 128\n",
        "}\n",
        "with open('model_config.pkl', 'wb') as f:\n",
        "    pickle.dump(config, f)\n",
        "print(\"✅ Config saved as 'model_config.pkl'\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ALL FILES SAVED SUCCESSFULLY!\")\n",
        "print(\"=\"*50)\n",
        "\n"
      ],
      "metadata": {
        "id": "M1ZIqj6jbPSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Predictions"
      ],
      "metadata": {
        "id": "XhNyi9gdbX6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_text(text, model, tokenizer, label_mapping, max_length):\n",
        "    \"\"\"Predict category for a given text with top-k predictions\"\"\"\n",
        "\n",
        "    # Preprocess\n",
        "    sequence = tokenizer.texts_to_sequences([text])\n",
        "    padded = pad_sequences(sequence, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "    # Predict\n",
        "    prediction = model.predict(padded, verbose=0)\n",
        "    pred_label = np.argmax(prediction[0])\n",
        "    confidence = prediction[0][pred_label]\n",
        "\n",
        "    # Get category name\n",
        "    category = label_mapping[label_mapping['label'] == pred_label]['category'].values[0]\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Text: {text[:150]}...\")\n",
        "    print(\"-\"*70)\n",
        "    print(f\"✅ Predicted Category: {category}\")\n",
        "    print(f\"✅ Confidence: {confidence*100:.2f}%\")\n",
        "    print(\"-\"*70)\n",
        "    print(\"Top 5 predictions:\")\n",
        "    top_5_idx = np.argsort(prediction[0])[-5:][::-1]\n",
        "    for rank, idx in enumerate(top_5_idx, 1):\n",
        "        cat = label_mapping[label_mapping['label'] == idx]['category'].values[0]\n",
        "        prob = prediction[0][idx] * 100\n",
        "        bar = \"█\" * int(prob / 2)\n",
        "        print(f\"  {rank}. {cat:20s} {prob:5.2f}% {bar}\")\n",
        "    print(\"=\"*70)\n",
        "    print()\n",
        "\n",
        "# Test with multiple examples\n",
        "test_texts = [\n",
        "    \"The Lakers won the championship game last night with an incredible performance\",\n",
        "    \"New study shows benefits of meditation for mental health and stress reduction\",\n",
        "    \"Stock market reaches all-time high today as investors remain optimistic\",\n",
        "    \"Tips for healthy eating and meal preparation for busy professionals\",\n",
        "    \"President announces new policy changes affecting international relations\",\n",
        "    \"Scientists discover breakthrough in renewable energy technology\",\n",
        "    \"Celebrity couple announces engagement on social media platform\",\n",
        "    \"Travel guide to the most beautiful destinations in Europe this summer\"\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"🔮 TESTING PREDICTIONS \".center(70, \"=\") + \"\\n\")\n",
        "\n",
        "for text in test_texts:\n",
        "    predict_text(text, model, tokenizer, label_mapping, MAX_SEQUENCE_LENGTH)\n"
      ],
      "metadata": {
        "id": "PI3GAriBbWs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Model Later (For Future Use)"
      ],
      "metadata": {
        "id": "_fzy34RDbelM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete loading script for later use\n",
        "from tensorflow import keras\n",
        "import pickle\n",
        "\n",
        "# Custom objects for loading model with attention layer\n",
        "custom_objects = {'AttentionLayer': AttentionLayer}\n",
        "\n",
        "# Load model\n",
        "loaded_model = keras.models.load_model(\n",
        "    'multichannel_cnn_attention.h5',\n",
        "    custom_objects=custom_objects\n",
        ")\n",
        "\n",
        "# Load tokenizer\n",
        "with open('tokenizer.pkl', 'rb') as f:\n",
        "    loaded_tokenizer = pickle.load(f)\n",
        "\n",
        "# Load label mapping\n",
        "with open('label_encoder.pkl', 'rb') as f:\n",
        "    loaded_label_mapping = pickle.load(f)\n",
        "\n",
        "# Load config\n",
        "with open('model_config.pkl', 'rb') as f:\n",
        "    loaded_config = pickle.load(f)\n",
        "\n",
        "print(\"✅ All components loaded successfully!\")\n",
        "print(f\"Model ready for predictions with {loaded_config['num_classes']} classes\")\n",
        "\n",
        "# Test prediction with loaded model\n",
        "predict_text(\n",
        "    \"Breaking news about political developments in Washington\",\n",
        "    loaded_model,\n",
        "    loaded_tokenizer,\n",
        "    loaded_label_mapping,\n",
        "    loaded_config['MAX_SEQUENCE_LENGTH']\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "zYqOLGm1bdtq",
        "outputId": "7d7e9a7c-f38f-490a-9a55-9160443fbaaa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'multichannel_cnn_attention.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2048674302.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m loaded_model = keras.models.load_model(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;34m'multichannel_cnn_attention.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 564\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'multichannel_cnn_attention.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Complete Quick Start Script"
      ],
      "metadata": {
        "id": "Q0LO5kdKblyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETE MULTI-CHANNEL CNN WITH ATTENTION - QUICK START\n",
        "\n",
        "!pip install tensorflow pandas scikit-learn -q\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, backend as K\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Custom Attention Layer\n",
        "class AttentionLayer(layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(name='attention_weight', shape=(input_shape[-1], input_shape[-1]), initializer='glorot_uniform', trainable=True)\n",
        "        self.b = self.add_weight(name='attention_bias', shape=(input_shape[-1],), initializer='zeros', trainable=True)\n",
        "        self.u = self.add_weight(name='attention_vector', shape=(input_shape[-1],), initializer='glorot_uniform', trainable=True)\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        uit = K.tanh(K.dot(x, self.W) + self.b)\n",
        "        ait = K.dot(uit, self.u)\n",
        "        attention_weights = K.softmax(ait, axis=1)\n",
        "        attention_weights = K.expand_dims(attention_weights, axis=-1)\n",
        "        weighted_input = x * attention_weights\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], input_shape[-1])\n",
        "\n",
        "# Load and prepare data\n",
        "df = pd.read_csv('news_preprocessed.csv')\n",
        "texts = df['text'].astype(str).tolist()\n",
        "labels = df['label'].values\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(texts, labels, test_size=0.2, random_state=42, stratify=labels)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Tokenize\n",
        "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_pad = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=200, padding='post')\n",
        "X_val_pad = pad_sequences(tokenizer.texts_to_sequences(X_val), maxlen=200, padding='post')\n",
        "X_test_pad = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=200, padding='post')\n",
        "\n",
        "# Build Multi-Channel CNN with Attention\n",
        "input_layer = layers.Input(shape=(200,))\n",
        "embedding = layers.Dropout(0.3)(layers.Embedding(10000, 128, input_length=200)(input_layer))\n",
        "\n",
        "conv_outputs = []\n",
        "for filter_size in [2, 3, 4, 5]:\n",
        "    conv = layers.Conv1D(128, filter_size, activation='relu', padding='same')(embedding)\n",
        "    conv = layers.BatchNormalization()(conv)\n",
        "    attention = AttentionLayer()(conv)\n",
        "    conv_outputs.append(attention)\n",
        "\n",
        "merged = layers.Concatenate()(conv_outputs)\n",
        "dense = layers.Dropout(0.5)(layers.Dense(512, activation='relu')(merged))\n",
        "dense = layers.Dropout(0.4)(layers.Dense(256, activation='relu')(dense))\n",
        "output = layers.Dense(15, activation='softmax')(dense)\n",
        "\n",
        "model = models.Model(inputs=input_layer, outputs=output)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "print(\"🚀 Training Multi-Channel CNN with Attention...\\n\")\n",
        "model.fit(X_train_pad, y_train, validation_data=(X_val_pad, y_val), epochs=20, batch_size=64,\n",
        "          callbacks=[EarlyStopping(patience=5, restore_best_weights=True), ModelCheckpoint('best_model.h5', save_best_only=True)])\n",
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate(X_test_pad, y_test)\n",
        "print(f\"\\n✅ Test Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
        "\n",
        "# Save\n",
        "model.save('multichannel_cnn_attention.h5')\n",
        "with open('tokenizer.pkl', 'wb') as f: pickle.dump(tokenizer, f)\n",
        "print(\"✅ Model and tokenizer saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "xa3TXoHFbkf8",
        "outputId": "77f4e049-b264-4767-cca3-13329a3ba235"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Training Multi-Channel CNN with Attention...\n",
            "\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "Exception encountered when calling AttentionLayer.call().\n\n\u001b[1mpop index out of range\u001b[0m\n\nArguments received by AttentionLayer.call():\n  • x=tf.Tensor(shape=(64, 200, 128), dtype=float32)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2848073495.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🚀 Training Multi-Channel CNN with Attention...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m model.fit(X_train_pad, y_train, validation_data=(X_val_pad, y_val), epochs=20, batch_size=64, \n\u001b[0m\u001b[1;32m     74\u001b[0m           callbacks=[EarlyStopping(patience=5, restore_best_weights=True), ModelCheckpoint('best_model.h5', save_best_only=True)])\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2848073495.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0muit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Exception encountered when calling AttentionLayer.call().\n\n\u001b[1mpop index out of range\u001b[0m\n\nArguments received by AttentionLayer.call():\n  • x=tf.Tensor(shape=(64, 200, 128), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mCeSbJvrbuVv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}